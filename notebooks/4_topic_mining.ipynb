{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfc18d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        title   tag    artist  year  views        features  \\\n",
      "0  Revelation  rock  Zardonic  2018   6680              {}   \n",
      "1  Robitussin    rb   OPENPAD  2017     94  {\"Rossi Rock\"}   \n",
      "\n",
      "                                              lyrics       id  \n",
      "0  [Intro]\\n(Try to do it like this, you won't ge...  3849758  \n",
      "1  Saucalini:\\n\\nBaby what you want, what you nee...  3387226  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "# Initialize counters\n",
    "topic_word_counts = defaultdict(Counter)\n",
    "background_word_count = Counter()\n",
    "\n",
    "# Load CSV and drop rows with NaN in 'tag' or 'lyrics' columns\n",
    "df = pd.read_csv('../data/2_ds2_trimmed.csv')\n",
    "df = df.dropna(subset=['tag', 'lyrics'])\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7baf674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cfc767872749be889583c25858acf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/99880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "valid_words = set(words.words())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Mangle the words coming in\n",
    "def tokenize(text, remove_stopwords=False, filter_non_words=True):\n",
    "    words = re.findall(r'\\b[a-zA-Z]{2,}\\b', text.lower())\n",
    "    if filter_non_words:\n",
    "        words = [word for word in words if word in valid_words]\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "    return words\n",
    "\n",
    "# Count words by topic and overall with a progress bar\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "    topic, lyrics = row['tag'], row['lyrics']\n",
    "    # Tokenize lyrics with stopword removal for topic counts\n",
    "    topic_words = tokenize(lyrics, remove_stopwords=True)\n",
    "    topic_word_counts[topic].update(topic_words)\n",
    "    # Tokenize without stopword removal for background count\n",
    "    background_words = tokenize(lyrics)\n",
    "    background_word_count.update(background_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82859a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0663916500804c00a9326b94dad54faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating topic models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic 'rock':\n",
      "  chorus: 0.012137634829860904\n",
      "  know: 0.0107365106657743\n",
      "  verse: 0.009982896309556845\n",
      "  oh: 0.00923200258278422\n",
      "  like: 0.009222026941486515\n",
      "  love: 0.007897080401855107\n",
      "  time: 0.007860805342590729\n",
      "  never: 0.0076159486925561765\n",
      "  one: 0.007324841341959543\n",
      "  go: 0.007094494715630742\n",
      "\n",
      "Top 10 words for topic 'rb':\n",
      "  love: 0.019655394236190886\n",
      "  yeah: 0.019618686675697126\n",
      "  know: 0.019276885128804423\n",
      "  oh: 0.017026892199523042\n",
      "  baby: 0.015485776422071955\n",
      "  like: 0.015179478909099443\n",
      "  chorus: 0.013229765859922745\n",
      "  got: 0.011544828656930538\n",
      "  verse: 0.010720412954037922\n",
      "  get: 0.0097058400525219\n",
      "\n",
      "Top 10 words for topic 'rap':\n",
      "  like: 0.017725415299780178\n",
      "  de: 0.012310372273715686\n",
      "  yeah: 0.012278771767317571\n",
      "  la: 0.011865990152492194\n",
      "  got: 0.011346063070660708\n",
      "  know: 0.010127468542683397\n",
      "  get: 0.009767025266579897\n",
      "  verse: 0.007500182690427614\n",
      "  bitch: 0.006718563914986738\n",
      "  ich: 0.006329482679959946\n",
      "\n",
      "Top 10 words for topic 'misc':\n",
      "  one: 0.007706677914931156\n",
      "  said: 0.005942311828448594\n",
      "  like: 0.005816484458829006\n",
      "  would: 0.005634004955968372\n",
      "  de: 0.005432840188108936\n",
      "  man: 0.004562981468590268\n",
      "  know: 0.004424233437003424\n",
      "  time: 0.0041201009322357\n",
      "  see: 0.0036843764548168427\n",
      "  could: 0.003683581337157319\n",
      "\n",
      "Top 10 words for topic 'pop':\n",
      "  oh: 0.013479909983384622\n",
      "  love: 0.012491499058056547\n",
      "  know: 0.012035509835036127\n",
      "  la: 0.011924335319709245\n",
      "  de: 0.011784498624649649\n",
      "  like: 0.010915947723658372\n",
      "  chorus: 0.009538425994686206\n",
      "  go: 0.0074686691976239925\n",
      "  yeah: 0.0072940904665247455\n",
      "  time: 0.0070561075196531355\n",
      "\n",
      "Top 10 words for topic 'country':\n",
      "  chorus: 0.01391522838518106\n",
      "  love: 0.013459240958545017\n",
      "  verse: 0.013130843018535272\n",
      "  like: 0.012160148003804487\n",
      "  know: 0.010797985246015728\n",
      "  oh: 0.009698250864128797\n",
      "  got: 0.00939885053471594\n",
      "  one: 0.007919972394274711\n",
      "  go: 0.007653919317048275\n",
      "  time: 0.007574175887906836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate unigram probabilities per topic\n",
    "topic_models = {}\n",
    "\n",
    "for topic, word_counts in tqdm(topic_word_counts.items(), desc=\"Calculating topic models\"):\n",
    "    topic_models[topic] = {}\n",
    "    total_topic_word_count = sum(word_counts.values())\n",
    "    for word, count in word_counts.items():\n",
    "        topic_models[topic][word] = count / total_topic_word_count\n",
    "        \n",
    "\n",
    "# Display Result\n",
    "\n",
    "# Loop through each topic and display the top 10 words by count ratio\n",
    "for topic, words in topic_models.items():\n",
    "    # Sort words by their values in descending order and get the top 10\n",
    "    top_words = sorted(words.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    # Print topic and the top 10 words with their values\n",
    "    print(f\"Top 10 words for topic '{topic}':\")\n",
    "    for word, value in top_words:\n",
    "        print(f\"  {word}: {value}\")\n",
    "    print()  # Add a newline for readability between topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405d44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 0.0497\n",
      "you: 0.0284\n",
      "and: 0.0278\n",
      "to: 0.0260\n",
      "of: 0.0204\n",
      "in: 0.0168\n",
      "it: 0.0166\n",
      "that: 0.0138\n",
      "me: 0.0138\n",
      "my: 0.0121\n"
     ]
    }
   ],
   "source": [
    "# Calculate background model probabilities\n",
    "total_background_count = sum(background_word_count.values())\n",
    "background_model = {word: count / total_background_count for word, count in background_word_count.items()}\n",
    "\n",
    "# Display results\n",
    "# Sort and print the top 10 words by frequency\n",
    "top_10_background = sorted(background_model.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for word, frequency in top_10_background:\n",
    "    print(f\"{word}: {frequency:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "437c8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "topic_models_path = '../data/models/topic_models.json'\n",
    "background_model_path = '../data/models/background_model.json'\n",
    "\n",
    "# Save topic_models as JSON\n",
    "with open(topic_models_path, 'w') as f:\n",
    "    json.dump(topic_models, f, indent=4)  # `indent=4` makes it human-readable\n",
    "\n",
    "# Save background_model as JSON\n",
    "with open(background_model_path, 'w') as f:\n",
    "    json.dump(background_model, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec38110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
