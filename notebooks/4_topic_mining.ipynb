{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ebce62-f5ad-4c4f-886c-9a83df8213be",
   "metadata": {},
   "source": [
    "Step 4 '4_topic_mining': In this step, we process song lyrics to calculate the most common words for each genre, creating a unigram topic model for each. The lyrics are tokenized with optional filters to remove stopwords and invalid words, ensuring meaningful analysis. For each genre, the frequency of words is normalized to represent the probability distribution of word occurrences. Additionally, we calculate the most common words across all genres to form a background model, which represents the overall distribution of words in the dataset. The results are stored as JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfc18d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        title   tag    artist  year  views        features  \\\n",
      "0  Revelation  rock  Zardonic  2018   6680              {}   \n",
      "1  Robitussin    rb   OPENPAD  2017     94  {\"Rossi Rock\"}   \n",
      "\n",
      "                                              lyrics       id  \n",
      "0  Try to do it like this, you won't get it Try t...  3849758  \n",
      "1  Saucalini:  Baby what you want, what you need?...  3387226  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "# Initialize counters\n",
    "topic_word_counts = defaultdict(Counter)\n",
    "background_word_count = Counter()\n",
    "\n",
    "# Load CSV and drop rows with NaN in 'tag' or 'lyrics' columns\n",
    "df = pd.read_csv('../data/3_ds3_cleaned.csv')\n",
    "df = df.dropna(subset=['tag', 'lyrics'])\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7baf674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0db66f99a5444eebc078944f8491f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/67606 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "valid_words = set(words.words())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Mangle the words coming in\n",
    "def tokenize(text, remove_stopwords=False, filter_non_words=True):\n",
    "    words = re.findall(r'\\b[a-zA-Z]{2,}\\b', text.lower())\n",
    "    if filter_non_words:\n",
    "        words = [word for word in words if word in valid_words]\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "    return words\n",
    "\n",
    "# Count words by topic and overall with a progress bar\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "    topic, lyrics = row['tag'], row['lyrics']\n",
    "    # Tokenize lyrics with stopword removal for topic counts\n",
    "    topic_words = tokenize(lyrics, remove_stopwords=True)\n",
    "    topic_word_counts[topic].update(topic_words)\n",
    "    # Tokenize without stopword removal for background count\n",
    "    background_words = tokenize(lyrics)\n",
    "    background_word_count.update(background_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82859a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96440b0c5fa7404b853871b51911c169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating topic models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic 'rock':\n",
      "  know: 0.01208772250939899\n",
      "  like: 0.010470906784314468\n",
      "  time: 0.008937193494026092\n",
      "  oh: 0.008756261610672457\n",
      "  love: 0.00875205389245493\n",
      "  never: 0.008644757077908006\n",
      "  one: 0.008274477874765682\n",
      "  see: 0.007913666037612793\n",
      "  go: 0.007846342546132371\n",
      "  got: 0.007027941352823484\n",
      "\n",
      "Top 10 words for topic 'rb':\n",
      "  know: 0.022522515811351396\n",
      "  love: 0.021878887655599342\n",
      "  like: 0.017795126602552166\n",
      "  yeah: 0.0166538785300844\n",
      "  baby: 0.016004290854371682\n",
      "  oh: 0.014460775184558884\n",
      "  got: 0.013589195390311311\n",
      "  get: 0.011135363046506605\n",
      "  let: 0.010550585150366137\n",
      "  want: 0.01020195323266711\n",
      "\n",
      "Top 10 words for topic 'rap':\n",
      "  like: 0.02547880922448938\n",
      "  got: 0.016341425641241903\n",
      "  know: 0.014328830928229331\n",
      "  get: 0.01379296304402042\n",
      "  yeah: 0.011957052043168994\n",
      "  bitch: 0.008511356109293782\n",
      "  go: 0.007899143411188077\n",
      "  see: 0.007029539626230333\n",
      "  back: 0.006771421445912608\n",
      "  cause: 0.006537297349962445\n",
      "\n",
      "Top 10 words for topic 'misc':\n",
      "  one: 0.008196599467922271\n",
      "  said: 0.006395790601195268\n",
      "  like: 0.0062090097317787935\n",
      "  would: 0.006056698226960515\n",
      "  know: 0.004740614799895644\n",
      "  man: 0.004660042660147361\n",
      "  time: 0.004388380980407829\n",
      "  could: 0.003960314558803982\n",
      "  see: 0.003876510916124618\n",
      "  us: 0.0035632705653385116\n",
      "\n",
      "Top 10 words for topic 'pop':\n",
      "  know: 0.015655556674543825\n",
      "  love: 0.015607544270949217\n",
      "  like: 0.014274907312640377\n",
      "  oh: 0.0124961063111719\n",
      "  go: 0.009334313879331948\n",
      "  time: 0.009166855983867832\n",
      "  one: 0.008516931983989619\n",
      "  let: 0.008417394074098363\n",
      "  get: 0.008396315457886095\n",
      "  got: 0.008349474088525504\n",
      "\n",
      "Top 10 words for topic 'country':\n",
      "  love: 0.014709731877421854\n",
      "  like: 0.013411364260578837\n",
      "  know: 0.011857672490795846\n",
      "  got: 0.010348279864267425\n",
      "  oh: 0.009770780124021492\n",
      "  one: 0.008689881028609998\n",
      "  go: 0.008365289124399242\n",
      "  time: 0.008340320516383032\n",
      "  get: 0.007938406471218847\n",
      "  back: 0.007578375252404437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate unigram probabilities per topic\n",
    "topic_models = {}\n",
    "\n",
    "for topic, word_counts in tqdm(topic_word_counts.items(), desc=\"Calculating topic models\"):\n",
    "    topic_models[topic] = {}\n",
    "    total_topic_word_count = sum(word_counts.values())\n",
    "    for word, count in word_counts.items():\n",
    "        topic_models[topic][word] = count / total_topic_word_count\n",
    "        \n",
    "\n",
    "# Display Result\n",
    "\n",
    "# Loop through each topic and display the top 10 words by count ratio\n",
    "for topic, words in topic_models.items():\n",
    "    # Sort words by their values in descending order and get the top 10\n",
    "    top_words = sorted(words.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    # Print topic and the top 10 words with their values\n",
    "    print(f\"Top 10 words for topic '{topic}':\")\n",
    "    for word, value in top_words:\n",
    "        print(f\"  {word}: {value}\")\n",
    "    print()  # Add a newline for readability between topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405d44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 0.0539\n",
      "you: 0.0305\n",
      "and: 0.0303\n",
      "to: 0.0278\n",
      "of: 0.0222\n",
      "it: 0.0179\n",
      "in: 0.0175\n",
      "that: 0.0151\n",
      "me: 0.0131\n",
      "my: 0.0130\n"
     ]
    }
   ],
   "source": [
    "# Calculate background model probabilities\n",
    "total_background_count = sum(background_word_count.values())\n",
    "background_model = {word: count / total_background_count for word, count in background_word_count.items()}\n",
    "\n",
    "# Display results\n",
    "# Sort and print the top 10 words by frequency\n",
    "top_10_background = sorted(background_model.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for word, frequency in top_10_background:\n",
    "    print(f\"{word}: {frequency:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "437c8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "topic_models_path = '../data/models/topic_models_nostopwords.json'\n",
    "background_model_path = '../data/models/background_model.json'\n",
    "\n",
    "# Save topic_models as JSON\n",
    "with open(topic_models_path, 'w') as f:\n",
    "    json.dump(topic_models, f, indent=4)  # `indent=4` makes it human-readable\n",
    "\n",
    "# Save background_model as JSON\n",
    "with open(background_model_path, 'w') as f:\n",
    "    json.dump(background_model, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec38110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
